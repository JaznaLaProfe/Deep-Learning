{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 31436,
          "sourceType": "datasetVersion",
          "datasetId": 19447
        }
      ],
      "dockerImageVersionId": 19668,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generación de Texto usando LSTM\n",
        "\n",
        "Adaptado de https://www.kaggle.com/code/shivamb/beginners-guide-to-text-generation-using-lstms/notebook\n",
        "\n",
        "\n",
        "**Autor:** Jazna Meza Hidalgo\n",
        "\n",
        "**Correo Electrónico:** ja.meza@profesor.duoc.cl\n",
        "\n",
        "**Fecha de Adaptación:** Junio 2025\n",
        "\n",
        "**Versión:** 1.0  \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Descripción\n",
        "\n",
        "\n",
        "Este notebook implementa una RNN para generación de texto.\n",
        "\n",
        "---\n",
        "\n",
        "## Requisitos de Software\n",
        "\n",
        "Este notebook fue desarrollado con Python 3.9. A continuación se listan las bibliotecas necesarias:\n",
        "\n",
        "-\n",
        "\n",
        "Para verificar la versión instalada ejecutar usando el siguiente comando, usando la librería de la cual quieres saber la versión:\n",
        "\n",
        "```bash\n",
        "import pandas as pd\n",
        "print(pd.__version__)\n",
        "````"
      ],
      "metadata": {
        "id": "G47REo8Z9Kuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "En este cuaderno, explicaremos cómo crear un modelo de lenguaje para generar texto en lenguaje natural mediante la implementación y el entrenamiento de una red neuronal recurrente de última generación.\n",
        "\n",
        "### Generación de titulares de noticias\n",
        "\n",
        "En este kernel, utilizaremos el conjunto de datos de [Comentarios y titulares del New York Times](https://www.kaggle.com/aashita/nyt-comments) para entrenar un modelo de lenguaje de generación de texto que se puede utilizar para generar titulares de noticias\n",
        "\n",
        "## 1. Importar las bibliotecas\n",
        "\n",
        "Como primer paso, debemos importar las bibliotecas necesarias:"
      ],
      "metadata": {
        "_uuid": "20c011dd401be7b6448c43f965e5d0bf548c53b9",
        "_cell_guid": "e084e610-8128-4769-ab64-6aa194044892",
        "id": "yWF_aYeU5_FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Configurar semillas para reproducibilidad\n",
        "import numpy as np\n",
        "import random\n",
        "tf.random.set_seed(2)  # Corrige la llamada obsoleta\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import string\n",
        "import os\n",
        "\n",
        "# Configurar warnings para evitar mensajes innecesarios\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "mWUrvgsV5_Fb"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Cargar los datos\n",
        "\n",
        "Cargar los datos desde los titulares"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "id": "1k68PcH25_Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p Articulos"
      ],
      "metadata": {
        "id": "hZbeoaGaRkK1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P Articulos https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesApril2017.csv\n",
        "!wget -P Articulos https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesApril2018.csv\n",
        "!wget -P Articulos https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesFeb2017.csv\n",
        "!wget -P Articulos https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesFeb2018.csv\n",
        "!wget -P Articulos https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesJan2017.csv\n",
        "!wget -P Articulos https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesJan2018.csv\n",
        "!wget -P Articulos https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesMarch2017.csv\n",
        "!wget -P Articulos https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesMarch2018.csv\n",
        "!wget -P Articulos https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesMay2017.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQMHdZCLQctJ",
        "outputId": "ce27b006-d5e0-40d0-9d89-4fca2daa1038"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-09 03:18:45--  https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesApril2017.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 429015 (419K) [text/plain]\n",
            "Saving to: ‘Articulos/ArticlesApril2017.csv’\n",
            "\n",
            "ArticlesApril2017.c 100%[===================>] 418.96K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-06-09 03:18:45 (6.14 MB/s) - ‘Articulos/ArticlesApril2017.csv’ saved [429015/429015]\n",
            "\n",
            "--2025-06-09 03:18:45--  https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesApril2018.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 692963 (677K) [text/plain]\n",
            "Saving to: ‘Articulos/ArticlesApril2018.csv’\n",
            "\n",
            "ArticlesApril2018.c 100%[===================>] 676.72K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-06-09 03:18:46 (8.82 MB/s) - ‘Articulos/ArticlesApril2018.csv’ saved [692963/692963]\n",
            "\n",
            "--2025-06-09 03:18:46--  https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesFeb2017.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 430986 (421K) [text/plain]\n",
            "Saving to: ‘Articulos/ArticlesFeb2017.csv’\n",
            "\n",
            "ArticlesFeb2017.csv 100%[===================>] 420.88K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-06-09 03:18:46 (6.74 MB/s) - ‘Articulos/ArticlesFeb2017.csv’ saved [430986/430986]\n",
            "\n",
            "--2025-06-09 03:18:46--  https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesFeb2018.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 594979 (581K) [text/plain]\n",
            "Saving to: ‘Articulos/ArticlesFeb2018.csv’\n",
            "\n",
            "ArticlesFeb2018.csv 100%[===================>] 581.03K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-06-09 03:18:46 (8.31 MB/s) - ‘Articulos/ArticlesFeb2018.csv’ saved [594979/594979]\n",
            "\n",
            "--2025-06-09 03:18:46--  https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesJan2017.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 412840 (403K) [text/plain]\n",
            "Saving to: ‘Articulos/ArticlesJan2017.csv’\n",
            "\n",
            "ArticlesJan2017.csv 100%[===================>] 403.16K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-06-09 03:18:47 (6.18 MB/s) - ‘Articulos/ArticlesJan2017.csv’ saved [412840/412840]\n",
            "\n",
            "--2025-06-09 03:18:47--  https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesJan2018.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 460669 (450K) [text/plain]\n",
            "Saving to: ‘Articulos/ArticlesJan2018.csv’\n",
            "\n",
            "ArticlesJan2018.csv 100%[===================>] 449.87K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-06-09 03:18:47 (6.50 MB/s) - ‘Articulos/ArticlesJan2018.csv’ saved [460669/460669]\n",
            "\n",
            "--2025-06-09 03:18:47--  https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesMarch2017.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 461113 (450K) [text/plain]\n",
            "Saving to: ‘Articulos/ArticlesMarch2017.csv’\n",
            "\n",
            "ArticlesMarch2017.c 100%[===================>] 450.31K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-06-09 03:18:48 (7.02 MB/s) - ‘Articulos/ArticlesMarch2017.csv’ saved [461113/461113]\n",
            "\n",
            "--2025-06-09 03:18:48--  https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesMarch2018.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 718307 (701K) [text/plain]\n",
            "Saving to: ‘Articulos/ArticlesMarch2018.csv’\n",
            "\n",
            "ArticlesMarch2018.c 100%[===================>] 701.47K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-06-09 03:18:48 (8.89 MB/s) - ‘Articulos/ArticlesMarch2018.csv’ saved [718307/718307]\n",
            "\n",
            "--2025-06-09 03:18:48--  https://raw.githubusercontent.com/JaznaLaProfe/Deep-Learning/main/data/Articulos/ArticlesMay2017.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 494124 (483K) [text/plain]\n",
            "Saving to: ‘Articulos/ArticlesMay2017.csv’\n",
            "\n",
            "ArticlesMay2017.csv 100%[===================>] 482.54K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-06-09 03:18:48 (6.64 MB/s) - ‘Articulos/ArticlesMay2017.csv’ saved [494124/494124]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curr_dir = '/content/Articulos'\n",
        "\n",
        "all_headlines = []\n",
        "for filename in os.listdir(curr_dir):\n",
        "    if 'Articles' in filename:\n",
        "        article_df = pd.read_csv(os.path.join(curr_dir, filename))\n",
        "        all_headlines.extend(list(article_df.headline.values))\n",
        "\n",
        "# Filtrar encabezados desconocidos\n",
        "all_headlines = [h for h in all_headlines if h != \"Unknown\"]\n",
        "print(f\"Total de encabezados válidos: {len(all_headlines)}\")\n"
      ],
      "metadata": {
        "_uuid": "87836e3adbe046dd0db62013491ba62bae93b6be",
        "_cell_guid": "b8ef1429-ff19-4a6c-92d7-af8cc61c55f7",
        "trusted": true,
        "id": "G5J8hRub5_Fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed28a16-e7c9-4991-ca03-c8279e393f92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de encabezados válidos: 8603\n"
          ]
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Preparación del conjunto de datos\n",
        "\n",
        "### 3.1 Limpieza del conjunto de datos\n",
        "\n",
        "En el paso de preparación del conjunto de datos, primero realizaremos una limpieza del texto de los datos, que incluye la eliminación de signos de puntuación y el cambio a minúsculas de todas las palabras."
      ],
      "metadata": {
        "_uuid": "fda5d4868631d3618d4d9a9a863541b2faf121c0",
        "_cell_guid": "9dbd8bc9-fb61-43b9-b0c4-98bd7f3f8150",
        "id": "sFQBB5Qn5_Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(txt):\n",
        "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
        "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return txt\n",
        "\n",
        "corpus = [clean_text(x) for x in all_headlines]\n",
        "corpus[:10]"
      ],
      "metadata": {
        "_uuid": "2a07365a27a7ba2f92fc9ba4d05d8e6254a68d8c",
        "_cell_guid": "b8bf84ed-da11-4f89-a584-9dceea677420",
        "trusted": true,
        "id": "F4rT189J5_Fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc58bb06-c794-475e-9597-8a867784191d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my beijing the sacred city',\n",
              " '6 million riders a day 1930s technology',\n",
              " 'seeking a crossborder conference',\n",
              " 'questions for despite the yuck factor leeches are big in russian medicine',\n",
              " 'who is a criminal',\n",
              " 'an antidote to europes populism',\n",
              " 'the cost of a speech',\n",
              " 'degradation of the language',\n",
              " 'on the power of being awful',\n",
              " 'trump garbles pitch on a revised health bill']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Generación de secuencias de tokens de N-gramas\n",
        "\n",
        "El modelado del lenguaje requiere una secuencia de datos de entrada, ya que dada una secuencia (de palabras/tokens), el objetivo es predecir la siguiente palabra/token.\n",
        "\n",
        "El siguiente paso es la tokenización. La tokenización es un proceso de extracción de tokens (términos/palabras) de un corpus. La biblioteca Keras de Python tiene un modelo incorporado para la tokenización que se puede utilizar para obtener los tokens y su índice en el corpus. Después de este paso, cada documento de texto en el conjunto de datos se convierte en una secuencia de tokens.\n"
      ],
      "metadata": {
        "_uuid": "6fd11859fd71aa5c7ce10bdbbd31c8eb6d1b3118",
        "_cell_guid": "9d83cc08-19ba-4b00-9ca6-dcf5ff39c8af",
        "id": "CQOxP98y5_Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "\n",
        "def get_sequence_of_tokens(corpus):\n",
        "    ## tokenization\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "    ## convert data to sequence of tokens\n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "    return input_sequences, total_words\n",
        "\n",
        "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
        "inp_sequences[:10]"
      ],
      "metadata": {
        "_uuid": "9129a8b773feb72eff91aa0025157a173d10c625",
        "_cell_guid": "896543c9-7944-4748-b8ef-ef8cbc2a84f0",
        "trusted": true,
        "id": "IMHmIj5N5_Fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e2baec-5d00-46b7-d8a0-9d2e87578a2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[46, 1601],\n",
              " [46, 1601, 1],\n",
              " [46, 1601, 1, 1951],\n",
              " [46, 1601, 1, 1951, 120],\n",
              " [122, 331],\n",
              " [122, 331, 1952],\n",
              " [122, 331, 1952, 2],\n",
              " [122, 331, 1952, 2, 125],\n",
              " [122, 331, 1952, 2, 125, 2484],\n",
              " [122, 331, 1952, 2, 125, 2484, 812]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la salida anterior, [30, 507], [30, 507, 11], [30, 507, 11, 1], etc., representan las frases ngram generadas a partir de los datos de entrada, donde cada entero corresponde al índice de una palabra particular en el vocabulario completo de palabras presentes en el texto. Por ejemplo\n",
        "\n",
        "**Headline:** i stand  with the shedevils  \n",
        "**Ngrams:** | **Sequence of Tokens**\n",
        "\n",
        "<table>\n",
        "<tr><td>Ngram </td><td> Sequence of Tokens</td></tr>\n",
        "<tr> <td>i stand </td><td> [30, 507] </td></tr>\n",
        "<tr> <td>i stand with </td><td> [30, 507, 11] </td></tr>\n",
        "<tr> <td>i stand with the </td><td> [30, 507, 11, 1] </td></tr>\n",
        "<tr> <td>i stand with the shedevils </td><td> [30, 507, 11, 1, 975] </td></tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "\n",
        "### 3.3 Relleno de secuencias y obtención de variables: predictores y objetivo\n",
        "\n",
        "Ahora que hemos generado un conjunto de datos que contiene una secuencia de tokens, es posible que las diferentes secuencias tengan longitudes diferentes. Antes de comenzar a entrenar el modelo, necesitamos rellenar las secuencias y hacer que sus longitudes sean iguales. Podemos usar la función pad_sequence de Keras para este propósito. Para ingresar estos datos en un modelo de aprendizaje, necesitamos crear predictores y etiquetas. Crearemos una secuencia de N-gramas como predictores y la siguiente palabra del N-grama como etiqueta. Por ejemplo:\n",
        "\n",
        "\n",
        "Titular:  they are learning data science\n",
        "\n",
        "<table>\n",
        "<tr><td>PREDICTORS </td> <td>           LABEL </td></tr>\n",
        "<tr><td>they                   </td> <td>  are</td></tr>\n",
        "<tr><td>they are               </td> <td>  learning</td></tr>\n",
        "<tr><td>they are learning      </td> <td>  data</td></tr>\n",
        "<tr><td>they are learning data </td> <td>  science</td></tr>\n",
        "</table>"
      ],
      "metadata": {
        "_uuid": "f22aa5e0c04620ca5034ab9389322eee543060c6",
        "_cell_guid": "a22c88f5-f2a3-457c-835b-63341e657e3f",
        "id": "WC9aLDKR5_Fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = keras.utils.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
      ],
      "metadata": {
        "_uuid": "ca588b414e70e21bebcead960f6632805d37dd8c",
        "_cell_guid": "73254551-40bd-45b1-a7a5-88fe4cbe0b20",
        "trusted": true,
        "id": "-J7KVIUC5_Fe"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfecto, ahora podemos obtener el vector de entrada X y el vector de etiqueta Y que se pueden utilizar para fines de entrenamiento.\n",
        "\n",
        "\n",
        "## 4. LSTM para generación de texto\n",
        "\n",
        "Diseñemos un modelo LSTM en nuestro código. Hemos agregado un total de tres capas al modelo.\n",
        "\n",
        "1. Capa de entrada: toma la secuencia de palabras como entrada\n",
        "2. Capa LSTM: calcula la salida utilizando unidades LSTM. Hemos añadido 100 unidades en la capa, pero este número se puede ajustar más adelante.\n",
        "3. Capa de abandono: una capa de regularización que desactiva aleatoriamente las activaciones de algunas neuronas en la capa LSTM. Ayuda a evitar el sobreajuste. (Capa opcional)\n",
        "4. Capa de salida: calcula la probabilidad de la mejor palabra siguiente posible como salida\n",
        "\n",
        "Ejecutaremos este modelo durante un total de 100 épocas, pero se puede experimentar más"
      ],
      "metadata": {
        "_uuid": "8b8a64b96011f427c48d5b0819e3e74af604ce43",
        "_cell_guid": "8b5d80ff-54a8-4380-8a3c-149be880551d",
        "id": "VhiVOMZm5_Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(max_sequence_len, total_words, model_name):\n",
        "    input_len = max_sequence_len - 1\n",
        "    model = tf.keras.models.Sequential(name=model_name)\n",
        "\n",
        "    # Add Input Embedding Layer\n",
        "    model.add(tf.keras.layers.Embedding(total_words, 10, input_length=input_len, name=\"Embedding\"))\n",
        "\n",
        "    # Add Hidden Layer 1 - LSTM Layer\n",
        "    model.add(tf.keras.layers.LSTM(100, name=\"CapaLSTM\"))\n",
        "    model.add(tf.keras.layers.Dropout(0.1, name=\"Dropout\"))\n",
        "\n",
        "    # Add Output Layer\n",
        "    model.add(tf.keras.layers.Dense(total_words, activation='softmax', name=\"Densa\"))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_model(max_sequence_len, total_words, \"generador\")\n",
        "model.summary()"
      ],
      "metadata": {
        "_uuid": "76ef6d9352002d333a7c75e8aed7ce996015f527",
        "_cell_guid": "60d6721e-e40e-4f2b-8f63-c06459d68f26",
        "trusted": true,
        "id": "JjlrOWZn5_Ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "227d67d6-b9aa-45d2-8cd8-4c438d61b885"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"generador\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"generador\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ CapaLSTM (\u001b[38;5;33mLSTM\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Densa (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ Embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ CapaLSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ Densa (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                           patience=3,  # Número de épocas sin mejora antes de detener\n",
        "                           restore_best_weights=True)\n"
      ],
      "metadata": {
        "id": "Uj8Z02mOS0b-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(predictors, label, epochs=100)\n"
      ],
      "metadata": {
        "_uuid": "156f3303b8120cc6932e6db985cbea4a7ceb08bf",
        "_cell_guid": "07d5cf03-d171-4993-9f8b-18446649ecb0",
        "trusted": true,
        "id": "NZaSrPL_5_Ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aea3e5e-326a-4aea-e6aa-dd53b40a477c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 35ms/step - loss: 8.0229\n",
            "Epoch 2/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - loss: 7.2757\n",
            "Epoch 3/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - loss: 7.0828\n",
            "Epoch 4/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 37ms/step - loss: 6.8969\n",
            "Epoch 5/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 36ms/step - loss: 6.7352\n",
            "Epoch 6/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 35ms/step - loss: 6.5788\n",
            "Epoch 7/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - loss: 6.4372\n",
            "Epoch 8/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 38ms/step - loss: 6.3459\n",
            "Epoch 9/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 36ms/step - loss: 6.2510\n",
            "Epoch 10/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 35ms/step - loss: 6.1559\n",
            "Epoch 11/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 35ms/step - loss: 6.0736\n",
            "Epoch 12/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 38ms/step - loss: 5.9310\n",
            "Epoch 13/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 37ms/step - loss: 5.7721\n",
            "Epoch 14/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 38ms/step - loss: 5.8580\n",
            "Epoch 15/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 36ms/step - loss: 5.6252\n",
            "Epoch 16/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 37ms/step - loss: 5.5143\n",
            "Epoch 17/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - loss: 5.3626\n",
            "Epoch 18/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 35ms/step - loss: 5.1820\n",
            "Epoch 19/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 35ms/step - loss: 5.0238\n",
            "Epoch 20/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 36ms/step - loss: 4.8874\n",
            "Epoch 21/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 36ms/step - loss: 4.7578\n",
            "Epoch 22/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 36ms/step - loss: 4.6273\n",
            "Epoch 23/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 35ms/step - loss: 4.5011\n",
            "Epoch 24/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 35ms/step - loss: 4.3845\n",
            "Epoch 25/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 35ms/step - loss: 4.2707\n",
            "Epoch 26/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 36ms/step - loss: 4.1614\n",
            "Epoch 27/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 35ms/step - loss: 4.0949\n",
            "Epoch 28/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - loss: 3.9626\n",
            "Epoch 29/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 37ms/step - loss: 3.8641\n",
            "Epoch 30/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 35ms/step - loss: 3.7828\n",
            "Epoch 31/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 36ms/step - loss: 3.7184\n",
            "Epoch 32/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 35ms/step - loss: 3.6450\n",
            "Epoch 33/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 37ms/step - loss: 3.5744\n",
            "Epoch 34/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 36ms/step - loss: 3.5312\n",
            "Epoch 35/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 37ms/step - loss: 3.4357\n",
            "Epoch 36/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 34ms/step - loss: 3.3710\n",
            "Epoch 37/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 35ms/step - loss: 3.3076\n",
            "Epoch 38/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 36ms/step - loss: 3.2961\n",
            "Epoch 39/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 35ms/step - loss: 3.2016\n",
            "Epoch 40/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - loss: 3.2578\n",
            "Epoch 41/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 37ms/step - loss: 3.9757\n",
            "Epoch 42/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 36ms/step - loss: 3.5585\n",
            "Epoch 43/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - loss: 3.3906\n",
            "Epoch 44/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 37ms/step - loss: 3.2504\n",
            "Epoch 45/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - loss: 3.1402\n",
            "Epoch 46/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 37ms/step - loss: 3.1502\n",
            "Epoch 47/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - loss: 3.0769\n",
            "Epoch 48/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 35ms/step - loss: 2.9908\n",
            "Epoch 49/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 36ms/step - loss: 2.9000\n",
            "Epoch 50/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 37ms/step - loss: 4.1618\n",
            "Epoch 51/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 36ms/step - loss: 4.2860\n",
            "Epoch 52/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - loss: 3.4787\n",
            "Epoch 53/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 37ms/step - loss: 3.2210\n",
            "Epoch 54/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 36ms/step - loss: 3.0666\n",
            "Epoch 55/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 37ms/step - loss: 2.9732\n",
            "Epoch 56/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 38ms/step - loss: 2.8463\n",
            "Epoch 57/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 37ms/step - loss: 2.7633\n",
            "Epoch 58/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 37ms/step - loss: 2.8174\n",
            "Epoch 59/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 36ms/step - loss: 2.7034\n",
            "Epoch 60/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - loss: 2.6196\n",
            "Epoch 61/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 35ms/step - loss: 2.5689\n",
            "Epoch 62/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 36ms/step - loss: 2.5235\n",
            "Epoch 63/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 35ms/step - loss: 2.4722\n",
            "Epoch 64/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 35ms/step - loss: 2.4213\n",
            "Epoch 65/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - loss: 2.3852\n",
            "Epoch 66/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 35ms/step - loss: 2.3716\n",
            "Epoch 67/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 36ms/step - loss: 2.3705\n",
            "Epoch 68/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 36ms/step - loss: 2.3439\n",
            "Epoch 69/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 35ms/step - loss: 2.2653\n",
            "Epoch 70/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - loss: 2.2350\n",
            "Epoch 71/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 36ms/step - loss: 2.2234\n",
            "Epoch 72/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - loss: 2.2193\n",
            "Epoch 73/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 37ms/step - loss: 2.1922\n",
            "Epoch 74/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 36ms/step - loss: 2.1536\n",
            "Epoch 75/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - loss: 2.1500\n",
            "Epoch 76/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 35ms/step - loss: 2.1510\n",
            "Epoch 77/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - loss: 2.1155\n",
            "Epoch 78/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 37ms/step - loss: 2.1053\n",
            "Epoch 79/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 36ms/step - loss: 2.1793\n",
            "Epoch 80/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - loss: 2.1772\n",
            "Epoch 81/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 37ms/step - loss: 2.0793\n",
            "Epoch 82/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 37ms/step - loss: 2.0555\n",
            "Epoch 83/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 37ms/step - loss: 2.0357\n",
            "Epoch 84/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 37ms/step - loss: 2.0222\n",
            "Epoch 85/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 36ms/step - loss: 2.0089\n",
            "Epoch 86/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - loss: 2.0243\n",
            "Epoch 87/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 35ms/step - loss: 2.0170\n",
            "Epoch 88/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - loss: 2.1350\n",
            "Epoch 89/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 36ms/step - loss: 2.0342\n",
            "Epoch 90/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 35ms/step - loss: 2.2449\n",
            "Epoch 91/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 36ms/step - loss: 2.5295\n",
            "Epoch 92/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 35ms/step - loss: 2.3543\n",
            "Epoch 93/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 35ms/step - loss: 2.7609\n",
            "Epoch 94/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 37ms/step - loss: 2.8376\n",
            "Epoch 95/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 36ms/step - loss: 2.5729\n",
            "Epoch 96/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 37ms/step - loss: 5.7591\n",
            "Epoch 97/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 36ms/step - loss: 4.7444\n",
            "Epoch 98/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 36ms/step - loss: 4.2573\n",
            "Epoch 99/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 35ms/step - loss: 3.8728\n",
            "Epoch 100/100\n",
            "\u001b[1m1618/1618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 35ms/step - loss: 3.3787\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('modelo_generador.keras')"
      ],
      "metadata": {
        "id": "BO8i81_NrnRl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "loss_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4EazWNesEDK",
        "outputId": "08730622-e722-4031-dd17-ab58e9f36c3c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7.85012674331665,\n",
              " 7.339392185211182,\n",
              " 7.077863693237305,\n",
              " 6.862645626068115,\n",
              " 6.686572074890137,\n",
              " 6.533481597900391,\n",
              " 6.391137599945068,\n",
              " 6.366805076599121,\n",
              " 6.2191267013549805,\n",
              " 6.141563415527344,\n",
              " 6.068075180053711,\n",
              " 5.9187421798706055,\n",
              " 5.822988033294678,\n",
              " 5.785533905029297,\n",
              " 5.586267471313477,\n",
              " 5.483320236206055,\n",
              " 5.306511878967285,\n",
              " 5.1365532875061035,\n",
              " 4.984583854675293,\n",
              " 4.847666263580322,\n",
              " 4.715892791748047,\n",
              " 4.591485023498535,\n",
              " 4.463147163391113,\n",
              " 4.3534746170043945,\n",
              " 4.23896598815918,\n",
              " 4.1577019691467285,\n",
              " 4.062850475311279,\n",
              " 3.938730001449585,\n",
              " 3.849604368209839,\n",
              " 3.7620766162872314,\n",
              " 3.6956889629364014,\n",
              " 3.6212213039398193,\n",
              " 3.5539278984069824,\n",
              " 3.5062084197998047,\n",
              " 3.4120304584503174,\n",
              " 3.3520894050598145,\n",
              " 3.29349946975708,\n",
              " 3.260896682739258,\n",
              " 3.1937718391418457,\n",
              " 3.5954411029815674,\n",
              " 3.907090187072754,\n",
              " 3.5674450397491455,\n",
              " 3.3938515186309814,\n",
              " 3.2519474029541016,\n",
              " 3.1424059867858887,\n",
              " 3.180879592895508,\n",
              " 3.0994369983673096,\n",
              " 3.005850315093994,\n",
              " 2.934981107711792,\n",
              " 4.230451583862305,\n",
              " 4.186967849731445,\n",
              " 3.409057140350342,\n",
              " 3.170656681060791,\n",
              " 3.0441975593566895,\n",
              " 2.9641916751861572,\n",
              " 2.8462038040161133,\n",
              " 2.7936336994171143,\n",
              " 2.8135197162628174,\n",
              " 2.686352491378784,\n",
              " 2.6158945560455322,\n",
              " 2.573037624359131,\n",
              " 2.525449514389038,\n",
              " 2.472424268722534,\n",
              " 2.435427665710449,\n",
              " 2.3973193168640137,\n",
              " 2.401601791381836,\n",
              " 2.4075980186462402,\n",
              " 2.3467562198638916,\n",
              " 2.27968430519104,\n",
              " 2.2489781379699707,\n",
              " 2.2308411598205566,\n",
              " 2.2154364585876465,\n",
              " 2.183248996734619,\n",
              " 2.1593518257141113,\n",
              " 2.1822245121002197,\n",
              " 2.1614930629730225,\n",
              " 2.1325104236602783,\n",
              " 2.1293187141418457,\n",
              " 2.256164789199829,\n",
              " 2.156177282333374,\n",
              " 2.076524496078491,\n",
              " 2.0590453147888184,\n",
              " 2.030531883239746,\n",
              " 2.029391050338745,\n",
              " 2.0435636043548584,\n",
              " 2.019752025604248,\n",
              " 2.125392198562622,\n",
              " 2.112943172454834,\n",
              " 2.064450979232788,\n",
              " 2.590549945831299,\n",
              " 2.5824055671691895,\n",
              " 2.3613247871398926,\n",
              " 3.1111748218536377,\n",
              " 2.751718282699585,\n",
              " 3.2260985374450684,\n",
              " 5.440473556518555,\n",
              " 4.605174541473389,\n",
              " 4.098226070404053,\n",
              " 3.9089255332946777,\n",
              " 3.2854530811309814]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('modelo_generador.keras')"
      ],
      "metadata": {
        "id": "TnDOell0rru9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Generación del texto\n",
        "\n",
        "Nuestra arquitectura de modelo ya está lista y podemos entrenarla usando nuestros datos. A continuación, escribamos la función para predecir la próxima palabra en función de las palabras de entrada (o texto inicial). Primero, tokenizaremos el texto inicial, rellenaremos las secuencias y lo pasaremos al modelo entrenado para obtener la palabra predicha. Las múltiples palabras predichas se pueden anexar para obtener la secuencia predicha.\n"
      ],
      "metadata": {
        "_uuid": "448bf43b123060dfe4e27cb9f12889e4fe0ed2a7",
        "_cell_guid": "61e99cfe-7395-4d61-8d1a-8539103d3db5",
        "id": "NjcdQGH85_Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        # Convertir el texto semilla a una secuencia de tokens\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        # Predecir la probabilidad para cada palabra\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted = np.argmax(predicted_probs, axis=-1)  # Obtener el índice de la palabra con la probabilidad más alta\n",
        "\n",
        "        # Buscar la palabra correspondiente al índice predicho\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "\n",
        "        # Añadir la palabra predicha al texto semilla\n",
        "        seed_text += \" \" + output_word\n",
        "\n",
        "    return seed_text.title()\n"
      ],
      "metadata": {
        "_uuid": "e71e56543b7065f115a05e3fd062262b3b94ad46",
        "trusted": true,
        "id": "JQpfD4Yr5_Ff"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Algunos resultados"
      ],
      "metadata": {
        "_uuid": "c49bf4ea0e54f3145149e164e243d897f545b84c",
        "_cell_guid": "ea0bddb6-acc6-4592-a2e0-ffc4129a582f",
        "id": "bsDuuTnf5_Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (generate_text(\"united states\", 5, model, max_sequence_len))\n",
        "print (generate_text(\"preident trump\", 4, model, max_sequence_len))\n",
        "print (generate_text(\"donald trump\", 4, model, max_sequence_len))\n",
        "print (generate_text(\"india and china\", 4, model, max_sequence_len))\n",
        "print (generate_text(\"new york\", 4, model, max_sequence_len))\n",
        "print (generate_text(\"science and technology\", 5, model, max_sequence_len))"
      ],
      "metadata": {
        "_uuid": "a21548224c9e661a29e3d369e348aada0599bdc9",
        "_cell_guid": "e38dd280-093b-4091-b82b-9aa90045b107",
        "trusted": true,
        "_kg_hide-input": true,
        "id": "8ICK1f9Y5_Fg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a9c1001-3d07-4dd0-9e65-cbdddf3eb773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States March Follow A Box And\n",
            "Preident Trump Is A Way To\n",
            "Donald Trump Is A Bear Lines\n",
            "India And China Services May Be A\n",
            "New York Today A Plethora Of\n",
            "Science And Technology Limits On The Cameras Of\n"
          ]
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desafíos\n",
        "\n",
        "Como podemos ver, el modelo ha producido un resultado que parece bastante bueno. Los resultados se pueden mejorar aún más con los siguientes puntos:\n",
        "- Agregar más datos\n",
        "- Ajustar la arquitectura de la red\n",
        "- Ajustar los parámetros de la red"
      ],
      "metadata": {
        "_uuid": "279f2e20c482b40d707413d0b1842f179a0d3d7b",
        "_cell_guid": "b2cfe563-974a-4e05-ad60-233d409d3de1",
        "id": "Mst9rpu65_Fg"
      }
    }
  ]
}