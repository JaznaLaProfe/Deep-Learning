{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gradiente descendente y backpropagation\n",
        "\n",
        "**Autor:** Jazna Meza Hidalgo\n",
        "\n",
        "**Correo Electrónico:** ja.meza@profesor.duoc.cl\n",
        "\n",
        "**Fecha de Creación:**  Febrero de 2025  \n",
        "**Versión:** 1.0  \n",
        "\n",
        "---\n",
        "\n",
        "## Descripción\n",
        "\n",
        "En este notebook se explica la relación de gradiente descendente y backpropagation y su importancia en el entrenamiento de una red neuronal.\n",
        "\n",
        "Previamente, se entrega una explicación simple de la regla de la cadena.\n",
        "\n",
        "Se implementa una red con la siguiente arquitectura:\n",
        "\n",
        "+ Una capa oculta\n",
        "+ Una neurona de salida\n",
        "\n",
        "Se va a usar backpropagation para ajustar los pesos.\n",
        "\n",
        "El objetivo de la red es aprender la función XOR\n",
        "---\n",
        "\n",
        "## Requisitos de Software\n",
        "\n",
        "Este notebook fue desarrollado con Python 3.9. A continuación se listan las bibliotecas necesarias:\n",
        "\n",
        "- numpy (1.26.4)\n",
        "- matplotlib (3.7.1)\n",
        "\n",
        "Para verificar la versión instalada ejecutar usando el nombre del paquete del cual quieres saber la versión; por ejemplo, si quieres saber la versión de sklearn usas:\n",
        "\n",
        "```bash\n",
        "import numpy\n",
        "print(numpy.__version__)\n",
        "````"
      ],
      "metadata": {
        "id": "N2vePrlD5R6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Concepto previo: la regla de la cadena\n",
        "\n",
        "Es un principio fundamental en cálculo que permite derivar funciones compuestas.\n",
        "\n",
        "En el contexto de redes neuronales y backpropagation se usa para calcular cómo un cambio en los pesos afecta a la función de pérdida.\n",
        "\n",
        "**Explicación matemática**\n",
        "\n",
        "Sea $z=f(g(x))$ una función compuesta, su derivada aplicando la regla de la cadena es:\n",
        "\n",
        "$\\frac{dz}{dx}=f'(g(x)) \\cdot g'(x)$\n",
        "\n",
        "**Ejemplo numérico**\n",
        "Sea $f(x)=(3x+2)^2$ entonces $g(x) = 3x+2$ y $f(u)=u^2$ donde $u=g(x)$\n",
        "\n",
        "Usando la regla de la cadena:\n",
        "\n",
        "$\\frac{df}{dx}=\\frac{df}{du}\\cdot\\frac{du}{dx}$\n",
        "\n",
        "Se calculan las derivadas:\n",
        "\n",
        "$\\frac{du}{dx}$ = 3\n",
        "\n",
        "$\\frac{df}{du}=2u=2(3x+2)$\n",
        "\n",
        "Por lo tanto, se tiene:\n",
        "\n",
        "$\\frac{df}{dx}=2(3x+2)\\cdot3=6(3x+2)$"
      ],
      "metadata": {
        "id": "0duAD72y-2up"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradiente descendente\n",
        "\n",
        "Algoritmo de optimización que ajusta los parámetros ($θ$) de un modelo para minimizar una función de pérdida (J($θ$)).\n",
        "\n",
        "Se basa en calcular el gradiente de la funciçon de pérdida respecto a los parámetros y actualizar los parámetros de esta forma:\n",
        "\n",
        "$\\theta = θ - α\\nabla J(θ)$\n",
        "\n",
        "donde:\n",
        "\n",
        "$\\alpha$ es la tasa de aprendizaje\n",
        "$∇ J(\\theta)$ es el gradiente de la función de pérdida respecto a $\\theta$\n",
        "\n",
        "**En redes neuronales, $θ$ representa los pesos y sesgos de las capas.**\n"
      ],
      "metadata": {
        "id": "64BTDLk96IwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation\n",
        "\n",
        "Es un método para calcular el gradiente de la función de pérdida respecto de los pesos de la red neuronal.\n",
        "\n",
        "**Funcionamiento**\n",
        "\n",
        "**1. Forward pass (propagación hacia adelante)**\n",
        "+ Se pasa una entrada *X* a través de la red y se obtiene una predicción $\\hat{y}$\n",
        "+ Se calcula la pérdida $J(\\theta)$ comparando $\\hat{y}$ con *y*\n",
        "\n",
        "**2. Backward pass (propagación hacia atrás)**\n",
        "+ Se usa la **regla de la cadena** para calcular como cambia $J(\\theta)$ con cada peso de la red.\n",
        "+ Se propagan estos gradientes entre la capa de salida hasta las capas ocultas.\n",
        "\n",
        "**3. Actualziación de pesos (gradiente descendente)**\n",
        "\n",
        "+ Con los gradientes calculados en Backpropagation, se aplcia **Gradiente Descendente** para ajustar los pesos:\n",
        "\n",
        "$W^{(l)}=W^{(l)}-α\\frac{δJ}{\\delta W^{(l)}}$\n",
        "\n",
        "donde:\n",
        "$W^{(l)}$ representa los pesos de la capa *l*\n",
        "$frac{δJ}{\\delta W^{(l)}}$ es el gradiente calculado en la propagación hacia atrás"
      ],
      "metadata": {
        "id": "wgkbzPA77c0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cómo trabajan juntos\n",
        "\n",
        "**Bakpropagation** es la técnica que permite calcular los gradientes de la función de pérdida respecto de los pesos.\n",
        "\n",
        "**Gradiente descendente** usa estos gradientes para actualizar los pesos y minimizar la pérdida.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*Sin backpropagation no sería posible aplicar gradiente descendente en redes profundas*.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jE2gmw9B93V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "qscBbdgU5ozb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función sigmoide y su derivada\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  return x * (1 - x)  # Regla de la cadena aplicada a la sigmoide\n",
        "\n",
        "# Datos de entrada\n",
        "x = np.array([[0.5]])  # Una característica\n",
        "W = np.array([[0.8]])  # Peso inicial\n",
        "b = np.array([[0.2]])  # Sesgo\n",
        "y_real = np.array([[1]])  # Valor esperado\n",
        "\n",
        "# Forward propagation\n",
        "z = np.dot(x, W) + b  # Entrada a la neurona\n",
        "a = sigmoid(z)         # Activación\n",
        "loss = (y_real - a)    # Error\n",
        "\n",
        "# Backpropagation con regla de la cadena\n",
        "dL_da = -1  # Derivada de la pérdida respecto a 'a' (asumiendo error cuadrático)\n",
        "da_dz = sigmoid_derivative(a)  # Derivada de 'a' respecto a 'z'\n",
        "dz_dW = x                      # Derivada de 'z' respecto a 'W'\n",
        "\n",
        "# Aplicando la regla de la cadena\n",
        "dL_dW = dL_da * da_dz * dz_dW\n",
        "\n",
        "# Gradiente para actualizar el peso\n",
        "learning_rate = 0.1\n",
        "W -= learning_rate * dL_dW  # Actualización del peso\n",
        "\n",
        "print(\"Nuevo peso ajustado:\", W)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rtRI7PuBmRj",
        "outputId": "9bf997a2-f051-4e6b-8806-bc82af812b36"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nuevo peso ajustado: [[0.81143921]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "❓**Por qué la derivada $\\frac{dL}{da}$ es -1**\n",
        "\n",
        "✅ Respuesta\n",
        "\n",
        "La función de pérdida cuadrática media (MSE) es:\n",
        "\n",
        "$L=\\frac{1}{2}(y_{real} - a)^2$\n",
        "\n",
        "donde:\n",
        "\n",
        "$y_{real}$ es el valor real\n",
        "\n",
        "$a$ es la salida de la neurona (predicción)\n",
        "\n",
        "Para aplicar backpropagation es necesario derivar la pérdida con respecto a la salida de la neurona ($a$):\n",
        "\n",
        "$\\frac{\\delta L}{\\delta a}=\\frac{\\delta}{\\delta a}(\\frac{1}{2}(y_{real}-a)^2)$\n",
        "\n",
        "Aplicando la regla de la cadena:\n",
        "\n",
        "$\\frac{\\delta L}{\\delta a}=\\frac{1}{2}\\cdot2(y_{real}-a)\\cdot(-1)$\n",
        "\n",
        "$\\frac{\\delta L}{\\delta a}=-(y_{real}-a)$"
      ],
      "metadata": {
        "id": "s1COnqMVESxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "**Comentarios**\n",
        "\n",
        "---\n",
        "\n",
        "✅ La regla de la cadena permite propagar los gradientes en backpropagation.\n",
        "\n",
        "✅ Se aplica desde la capa de salida hasta la capa de entrada, ajustando los pesos usando gradiente descendente.\n",
        "\n",
        "✅ Cada derivada representa cómo cambia la pérdida respecto a los parámetros de la red.\n",
        "\n",
        "⭐ **¡Esto es la base del aprendizaje profundo en redes neuronales!** ⭐\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zRPZ9qgXB22M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#El problema del XOR"
      ],
      "metadata": {
        "id": "a0LshRX-GxyD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJpBQTTo5D3Y",
        "outputId": "71d21a22-830e-4441-d3be-3aa5e5380ec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Error 0.4978\n",
            "Epoch 1000: Error 0.1119\n",
            "Epoch 2000: Error 0.0504\n",
            "Epoch 3000: Error 0.0366\n",
            "Epoch 4000: Error 0.0300\n",
            "Epoch 5000: Error 0.0259\n",
            "Epoch 6000: Error 0.0231\n",
            "Epoch 7000: Error 0.0211\n",
            "Epoch 8000: Error 0.0195\n",
            "Epoch 9000: Error 0.0182\n",
            "\n",
            "Salida final después del entrenamiento:\n",
            "[[0.01890475]\n",
            " [0.98371361]\n",
            " [0.98369334]\n",
            " [0.01686123]]\n"
          ]
        }
      ],
      "source": [
        "# Función de activación Sigmoide y su derivada\n",
        "def sigmoid(x: float):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x: float):\n",
        "    return x * (1 - x)  # Derivada de la sigmoide\n",
        "\n",
        "# Datos de entrada (XOR)\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])  # 4 ejemplos, 2 características\n",
        "y = np.array([[0], [1], [1], [0]])  # Salidas esperadas\n",
        "\n",
        "# Inicialización de pesos y sesgos aleatorios\n",
        "np.random.seed(42)\n",
        "W1 = np.random.rand(2, 2)  # Pesos de la capa oculta (2x2)\n",
        "b1 = np.random.rand(1, 2)  # Sesgo de la capa oculta\n",
        "W2 = np.random.rand(2, 1)  # Pesos de la capa de salida (2x1)\n",
        "b2 = np.random.rand(1, 1)  # Sesgo de la capa de salida\n",
        "\n",
        "# Hiperparámetros\n",
        "alpha = 0.5  # Tasa de aprendizaje\n",
        "epochs = 10000  # Número de iteraciones\n",
        "\n",
        "# Entrenamiento con backpropagation y gradiente descendente\n",
        "for epoch in range(epochs):\n",
        "    # FORWARD PROPAGATION\n",
        "    Z1 = np.dot(X, W1) + b1  # Entrada de la capa oculta\n",
        "    A1 = sigmoid(Z1)         # Activación de la capa oculta\n",
        "    Z2 = np.dot(A1, W2) + b2 # Entrada de la capa de salida\n",
        "    A2 = sigmoid(Z2)         # Salida de la red\n",
        "\n",
        "    # Cálculo del error\n",
        "    error = y - A2\n",
        "\n",
        "    # BACKPROPAGATION\n",
        "    dA2 = error * sigmoid_derivative(A2)  # Gradiente en la capa de salida\n",
        "    dW2 = np.dot(A1.T, dA2)               # Gradiente respecto a W2\n",
        "    db2 = np.sum(dA2, axis=0, keepdims=True)\n",
        "\n",
        "    dA1 = np.dot(dA2, W2.T) * sigmoid_derivative(A1)  # Gradiente en la capa oculta\n",
        "    dW1 = np.dot(X.T, dA1)                            # Gradiente respecto a W1\n",
        "    db1 = np.sum(dA1, axis=0, keepdims=True)\n",
        "\n",
        "    # ACTUALIZACIÓN DE PESOS (Gradiente Descendente)\n",
        "    W2 += alpha * dW2\n",
        "    b2 += alpha * db2\n",
        "    W1 += alpha * dW1\n",
        "    b1 += alpha * db1\n",
        "\n",
        "    # Mostrar error cada 1000 iteraciones\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.abs(error))\n",
        "        print(f\"Epoch {epoch}: Error {loss:.4f}\")\n",
        "\n",
        "# RESULTADOS\n",
        "print(\"\\nSalida final después del entrenamiento:\")\n",
        "print(A2)\n"
      ]
    }
  ]
}